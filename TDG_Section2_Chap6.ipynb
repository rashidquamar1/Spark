{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RuVx-7cqxKex",
        "BE1VTrKe0iiH",
        "_hC1SL9Y6JwE",
        "HYt3eFp28d25",
        "gaxjmkOZ9v2M",
        "-a6L3LWACA7y",
        "2-XyRDz7VAyD"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"CSV_Read\").getOrCreate()\n",
        "\n",
        "df = spark.read.format(\"csv\")\\\n",
        " .option(\"header\", \"true\")\\\n",
        " .option(\"inferSchema\", \"true\")\\\n",
        " .load(\"/content/2010-12-01.csv\")\n",
        "\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2JfTOBMvdjc",
        "outputId": "67bbbc4b-cce7-4833-ca45-fc43bb1017ed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- InvoiceNo: string (nullable = true)\n",
            " |-- StockCode: string (nullable = true)\n",
            " |-- Description: string (nullable = true)\n",
            " |-- Quantity: integer (nullable = true)\n",
            " |-- InvoiceDate: timestamp (nullable = true)\n",
            " |-- UnitPrice: double (nullable = true)\n",
            " |-- CustomerID: double (nullable = true)\n",
            " |-- Country: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-z_rcBJxi8t",
        "outputId": "35708cab-6063-4518-cd5d-b505263f2943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3108"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"dfTable\")"
      ],
      "metadata": {
        "id": "rH1iTMYgvgp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select * from dfTable\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHIUsh8jv-BS",
        "outputId": "6fc577e4-1932-4558-c2b0-e4d3cbe2172d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
            "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
            "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
            "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n",
            "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
            "|   536365|   84406B|CREAM CUPID HEART...|       8|2010-12-01 08:26:00|     2.75|   17850.0|United Kingdom|\n",
            "|   536365|   84029G|KNITTED UNION FLA...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
            "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
            "|   536365|    22752|SET 7 BABUSHKA NE...|       2|2010-12-01 08:26:00|     7.65|   17850.0|United Kingdom|\n",
            "|   536365|    21730|GLASS STAR FROSTE...|       6|2010-12-01 08:26:00|     4.25|   17850.0|United Kingdom|\n",
            "|   536366|    22633|HAND WARMER UNION...|       6|2010-12-01 08:28:00|     1.85|   17850.0|United Kingdom|\n",
            "|   536366|    22632|HAND WARMER RED P...|       6|2010-12-01 08:28:00|     1.85|   17850.0|United Kingdom|\n",
            "|   536367|    84879|ASSORTED COLOUR B...|      32|2010-12-01 08:34:00|     1.69|   13047.0|United Kingdom|\n",
            "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
            "only showing top 10 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMxjzbxRu0sB",
        "outputId": "2d5b49ca-9aa5-482a-db6c-6d8fa01bb259"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+---+---------+---------+\n",
            "|  5|five|5.0|InvoiceNo|StockCode|\n",
            "+---+----+---+---------+---------+\n",
            "|  5|five|5.0|   536365|   85123A|\n",
            "|  5|five|5.0|   536365|    71053|\n",
            "|  5|five|5.0|   536365|   84406B|\n",
            "|  5|five|5.0|   536365|   84029G|\n",
            "|  5|five|5.0|   536365|   84029E|\n",
            "+---+----+---+---------+---------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import lit,col\n",
        "\n",
        "df.select(lit(5), lit(\"five\"), lit(5.0),col(\"InvoiceNo\"),col(\"StockCode\")).show(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-A9Hk7Bywp6p",
        "outputId": "3566804a-25ff-4aae-c47f-f0b857b4c736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- InvoiceNo: string (nullable = true)\n",
            " |-- StockCode: string (nullable = true)\n",
            " |-- Description: string (nullable = true)\n",
            " |-- Quantity: integer (nullable = true)\n",
            " |-- InvoiceDate: timestamp (nullable = true)\n",
            " |-- UnitPrice: double (nullable = true)\n",
            " |-- CustomerID: double (nullable = true)\n",
            " |-- Country: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Working with Boolean"
      ],
      "metadata": {
        "id": "RuVx-7cqxKex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "'''\n",
        "df.where(col(\"InvoiceNo\") != 536365)\\\n",
        " .select(\"InvoiceNo\", \"Description\")\\\n",
        " .show(50, False)\n",
        "'''\n",
        "df.selectExpr(\"InvoiceNo\", \"Description\",\"Description\",\"Quantity\")\\\n",
        ".where(col(\"InvoiceNo\")!=536365)\\\n",
        ".show(10)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8ywy5WAxTEx",
        "outputId": "d708bcb7-c84a-41ad-bd27-e1c3ce335197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------------------+--------------------+--------+\n",
            "|InvoiceNo|         Description|         Description|Quantity|\n",
            "+---------+--------------------+--------------------+--------+\n",
            "|   536366|HAND WARMER UNION...|HAND WARMER UNION...|       6|\n",
            "|   536366|HAND WARMER RED P...|HAND WARMER RED P...|       6|\n",
            "|   536367|ASSORTED COLOUR B...|ASSORTED COLOUR B...|      32|\n",
            "|   536367|POPPY'S PLAYHOUSE...|POPPY'S PLAYHOUSE...|       6|\n",
            "|   536367|POPPY'S PLAYHOUSE...|POPPY'S PLAYHOUSE...|       6|\n",
            "|   536367|FELTCRAFT PRINCES...|FELTCRAFT PRINCES...|       8|\n",
            "|   536367|IVORY KNITTED MUG...|IVORY KNITTED MUG...|       6|\n",
            "|   536367|BOX OF 6 ASSORTED...|BOX OF 6 ASSORTED...|       6|\n",
            "|   536367|BOX OF VINTAGE JI...|BOX OF VINTAGE JI...|       3|\n",
            "|   536367|BOX OF VINTAGE AL...|BOX OF VINTAGE AL...|       2|\n",
            "+---------+--------------------+--------------------+--------+\n",
            "only showing top 10 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.selectExpr(\"InvoiceNo\", \"Description\",\"Description\",\"Quantity\")\\\n",
        ".where(\"InvoiceNo <> 536365\")\\\n",
        ".show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QWBXn6TzHTI",
        "outputId": "8e5afb3a-a0e5-4b71-bb33-6e12bf454d3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------------------+--------------------+--------+\n",
            "|InvoiceNo|         Description|         Description|Quantity|\n",
            "+---------+--------------------+--------------------+--------+\n",
            "|   536366|HAND WARMER UNION...|HAND WARMER UNION...|       6|\n",
            "|   536366|HAND WARMER RED P...|HAND WARMER RED P...|       6|\n",
            "|   536367|ASSORTED COLOUR B...|ASSORTED COLOUR B...|      32|\n",
            "|   536367|POPPY'S PLAYHOUSE...|POPPY'S PLAYHOUSE...|       6|\n",
            "|   536367|POPPY'S PLAYHOUSE...|POPPY'S PLAYHOUSE...|       6|\n",
            "|   536367|FELTCRAFT PRINCES...|FELTCRAFT PRINCES...|       8|\n",
            "|   536367|IVORY KNITTED MUG...|IVORY KNITTED MUG...|       6|\n",
            "|   536367|BOX OF 6 ASSORTED...|BOX OF 6 ASSORTED...|       6|\n",
            "|   536367|BOX OF VINTAGE JI...|BOX OF VINTAGE JI...|       3|\n",
            "|   536367|BOX OF VINTAGE AL...|BOX OF VINTAGE AL...|       2|\n",
            "+---------+--------------------+--------------------+--------+\n",
            "only showing top 10 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.selectExpr(\"InvoiceNo\", \"Description\",\"Description\",\"Quantity\")\\\n",
        ".where(\"InvoiceNo = '536366'\")\\\n",
        ".show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuiykFQ4z5EL",
        "outputId": "d1d4e12f-bcc7-47e3-d280-2d95a8b39c40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------------------+--------------------+--------+\n",
            "|InvoiceNo|         Description|         Description|Quantity|\n",
            "+---------+--------------------+--------------------+--------+\n",
            "|   536366|HAND WARMER UNION...|HAND WARMER UNION...|       6|\n",
            "|   536366|HAND WARMER RED P...|HAND WARMER RED P...|       6|\n",
            "+---------+--------------------+--------------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import instr\n",
        "\n",
        "priceFilter = col(\"UnitPrice\") > 600\n",
        "descripFilter = instr(df.Description, \"POSTAGE\") >= 1\n",
        "df.where(df.StockCode.isin(\"DOT\")).where(priceFilter | descripFilter).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmRuXkKj0DVD",
        "outputId": "ca5557ff-2f2d-45e7-b3c8-65ad2396aa11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
            "|InvoiceNo|StockCode|   Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
            "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
            "|   536544|      DOT|DOTCOM POSTAGE|       1|2010-12-01 14:32:00|   569.77|      NULL|United Kingdom|\n",
            "|   536592|      DOT|DOTCOM POSTAGE|       1|2010-12-01 17:06:00|   607.49|      NULL|United Kingdom|\n",
            "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.where(df.StockCode.isin(\"DOT\")).where(priceFilter).where(descripFilter).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1FcqAKp0OHo",
        "outputId": "9b13ec50-e83a-44de-cba1-85177e0bfccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
            "|InvoiceNo|StockCode|   Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
            "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
            "|   536592|      DOT|DOTCOM POSTAGE|       1|2010-12-01 17:06:00|   607.49|      NULL|United Kingdom|\n",
            "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HX-v34ZH0VUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working with Numbers"
      ],
      "metadata": {
        "id": "BE1VTrKe0iiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import expr, pow,round\n",
        "\n",
        "fabricatedQuantity = pow(col(\"Quantity\") * col(\"UnitPrice\"), 2) + 5\n",
        "df.select(expr(\"CustomerId\"),expr(\"Quantity\"),expr(\"UnitPrice\"),expr(\"Description\"), round(fabricatedQuantity,2).alias(\"realQuantity\")).show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zb-JMxAq0nuN",
        "outputId": "32b5cc43-c843-4542-8f73-977459df4110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+---------+--------------------+------------+\n",
            "|CustomerId|Quantity|UnitPrice|         Description|realQuantity|\n",
            "+----------+--------+---------+--------------------+------------+\n",
            "|   17850.0|       6|     2.55|WHITE HANGING HEA...|      239.09|\n",
            "|   17850.0|       6|     3.39| WHITE METAL LANTERN|      418.72|\n",
            "+----------+--------+---------+--------------------+------------+\n",
            "only showing top 2 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fabricatedQuantity = round((pow(col(\"Quantity\") * col(\"UnitPrice\"), 2) + 5),2)\n",
        "df.selectExpr(\"CustomerId\",\"Quantity\",\"UnitPrice\",\"Description\", fabricatedQuantity.alias(\"realQuantity\")).show(2)\n",
        "#Note : selectExpr() accepts ONLY strings (SQL expressions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "BNB_gAKR1cU9",
        "outputId": "4195d6d9-465d-4b04-9bc0-fc201b66b9b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "PySparkTypeError",
          "evalue": "[NOT_ITERABLE] Column is not iterable.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPySparkTypeError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-452855433.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfabricatedQuantity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Quantity\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"UnitPrice\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselectExpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CustomerId\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Quantity\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"UnitPrice\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Description\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfabricatedQuantity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"realQuantity\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#Note : selectExpr() accepts ONLY strings (SQL expressions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/sql/classic/dataframe.py\u001b[0m in \u001b[0;36mselectExpr\u001b[0;34m(self, *expr)\u001b[0m\n\u001b[1;32m   1003\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0mexpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# type: ignore[assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselectExpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jseq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1006\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/sql/classic/dataframe.py\u001b[0m in \u001b[0;36m_jseq\u001b[0;34m(self, cols, converter)\u001b[0m\n\u001b[1;32m    875\u001b[0m     ) -> \"JavaObject\":\n\u001b[1;32m    876\u001b[0m         \u001b[0;34m\"\"\"Return a JVM Seq of Columns from a list of Column or names\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_to_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_jmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"JavaObject\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/sql/classic/column.py\u001b[0m in \u001b[0;36m_to_seq\u001b[0;34m(sc, cols, converter)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1354\u001b[0;31m         \u001b[0margs_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m         \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCALL_COMMAND_NAME\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_build_args\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mnew_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_args\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcan_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m                         \u001b[0mtemp_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m                         \u001b[0mtemp_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m                         \u001b[0mnew_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/py4j/java_collections.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, object, gateway_client)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0mjava_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArrayList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mjava_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjava_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1354\u001b[0;31m         \u001b[0margs_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m         \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCALL_COMMAND_NAME\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_build_args\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mnew_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_args\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcan_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m                         \u001b[0mtemp_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m                         \u001b[0mtemp_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m                         \u001b[0mnew_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/py4j/java_collections.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, object, gateway_client)\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0mArrayList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJavaClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"java.util.ArrayList\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0mjava_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArrayList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m             \u001b[0mjava_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjava_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/sql/classic/column.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         raise PySparkTypeError(\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0merrorClass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"NOT_ITERABLE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessageParameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"objectName\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Column\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         )\n",
            "\u001b[0;31mPySparkTypeError\u001b[0m: [NOT_ITERABLE] Column is not iterable."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.selectExpr(\n",
        " \"CustomerId\",\"Quantity\",\"UnitPrice\",\"Description\",\n",
        " \"(POWER((Quantity * UnitPrice), 2.0) + 5) as realQuantity\").show(2)\n",
        "\n",
        "'''\n",
        "in SQL\n",
        "SELECT customerId, (POWER((Quantity * UnitPrice), 2.0) + 5) as realQuantity\n",
        "FROM dfTabl\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "_g-aFNr55IqT",
        "outputId": "87e06f86-04c4-4147-c64f-79f698922d40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+---------+--------------------+------------------+\n",
            "|CustomerId|Quantity|UnitPrice|         Description|      realQuantity|\n",
            "+----------+--------+---------+--------------------+------------------+\n",
            "|   17850.0|       6|     2.55|WHITE HANGING HEA...|239.08999999999997|\n",
            "|   17850.0|       6|     3.39| WHITE METAL LANTERN|          418.7156|\n",
            "+----------+--------+---------+--------------------+------------------+\n",
            "only showing top 2 rows\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nin SQL\\nSELECT customerId, (POWER((Quantity * UnitPrice), 2.0) + 5) as realQuantity\\nFROM dfTabl\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import corr\n",
        "# Pearson Coeffieint(k)\n",
        "df.stat.corr(\"Quantity\", \"UnitPrice\")\n",
        "df.select(corr(\"Quantity\", \"UnitPrice\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaVuzfqg5gjb",
        "outputId": "b7fd1e1e-12c7-48ae-a375-5a2057b966fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------+\n",
            "|corr(Quantity, UnitPrice)|\n",
            "+-------------------------+\n",
            "|     -0.04112314436835551|\n",
            "+-------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #common task is to compute summary statistics for a column or set of columns.\n",
        "df.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtT2VuDe6BUC",
        "outputId": "7b9967f6-5705-444c-9dd0-4d42bc041377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+------------------+--------------------+------------------+------------------+------------------+--------------+\n",
            "|summary|        InvoiceNo|         StockCode|         Description|          Quantity|         UnitPrice|        CustomerID|       Country|\n",
            "+-------+-----------------+------------------+--------------------+------------------+------------------+------------------+--------------+\n",
            "|  count|             3108|              3108|                3098|              3108|              3108|              1968|          3108|\n",
            "|   mean| 536516.684944841|27834.304044117645|                NULL| 8.627413127413128| 4.151946589446603|15661.388719512195|          NULL|\n",
            "| stddev|72.89447869788873|17407.897548583845|                NULL|26.371821677029203|15.638659854603892|1854.4496996893627|          NULL|\n",
            "|    min|           536365|             10002| 4 PURPLE FLOCK D...|               -24|               0.0|           12431.0|     Australia|\n",
            "|    max|          C536548|              POST|ZINC WILLIE WINKI...|               600|            607.49|           18229.0|United Kingdom|\n",
            "+-------+-----------------+------------------+--------------------+------------------+------------------+------------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Working with Strings"
      ],
      "metadata": {
        "id": "_hC1SL9Y6JwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import initcap, col\n",
        "\n",
        "#making all strings uppercase or lowercase\n",
        "df.select(initcap(col(\"Description\"))).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpkQTI5h6Ts-",
        "outputId": "5ecaeac4-a81b-4689-c461-9591a478da09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|initcap(Description)|\n",
            "+--------------------+\n",
            "|White Hanging Hea...|\n",
            "| White Metal Lantern|\n",
            "|Cream Cupid Heart...|\n",
            "|Knitted Union Fla...|\n",
            "|Red Woolly Hottie...|\n",
            "+--------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, lower, upper\n",
        "\n",
        "df.select(col(\"Description\"),\n",
        "  lower(col(\"Description\")),\n",
        "  upper(lower(col(\"Description\")))).show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueFAVsFq8C0S",
        "outputId": "58422ffa-da5e-47b9-bc63-3d4881c384fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-------------------------+\n",
            "|         Description|  lower(Description)|upper(lower(Description))|\n",
            "+--------------------+--------------------+-------------------------+\n",
            "|WHITE HANGING HEA...|white hanging hea...|     WHITE HANGING HEA...|\n",
            "| WHITE METAL LANTERN| white metal lantern|      WHITE METAL LANTERN|\n",
            "+--------------------+--------------------+-------------------------+\n",
            "only showing top 2 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lit, ltrim, rtrim, rpad, lpad, trim\n",
        "\n",
        "df.select(\n",
        "    ltrim(lit(\"    HELLO    \")).alias(\"ltrim\"),\n",
        "    rtrim(lit(\"    HELLO    \")).alias(\"rtrim\"),\n",
        "    trim(lit(\"    HELLO    \")).alias(\"trim\"),\n",
        "    lpad(lit(\"HELLO\"), 3, \" \").alias(\"lp\"),\n",
        "    rpad(lit(\"HELLO\"), 10, \" \").alias(\"rp\")).show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buHak1dY8OgQ",
        "outputId": "285de82c-1f77-4588-efcf-48d30d0c84c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+-----+---+----------+\n",
            "|    ltrim|    rtrim| trim| lp|        rp|\n",
            "+---------+---------+-----+---+----------+\n",
            "|HELLO    |    HELLO|HELLO|HEL|HELLO     |\n",
            "|HELLO    |    HELLO|HELLO|HEL|HELLO     |\n",
            "+---------+---------+-----+---+----------+\n",
            "only showing top 2 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Regular Expression"
      ],
      "metadata": {
        "id": "HYt3eFp28d25"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regular expressions give\n",
        " the user an ability to specify a set of rules to use to either extract values from a string or replace them with some other values.\n",
        "\n",
        "  There are two key functions in Spark that youâ€™ll need in\n",
        " order to perform regular expression tasks:\n",
        " **regexp_extract** and **regexp_replace**.\n",
        "\n",
        " These functions extract values and replace values, respectively"
      ],
      "metadata": {
        "id": "gPqplIc08iyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import regexp_replace\n",
        "\n",
        "regex_string = \"BLACK|WHITE|RED|GREEN|BLUE\"\n",
        "\n",
        "df.select(regexp_replace(col(\"Description\"), regex_string, \"COLOR\").alias(\"color_clean\"),col(\"Description\")).show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4907c6wL8aQr",
        "outputId": "a011f2f0-abd7-45f5-c6fc-4eec1ef9c1f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+\n",
            "|         color_clean|         Description|\n",
            "+--------------------+--------------------+\n",
            "|COLOR HANGING HEA...|WHITE HANGING HEA...|\n",
            "| COLOR METAL LANTERN| WHITE METAL LANTERN|\n",
            "|CREAM CUPID HEART...|CREAM CUPID HEART...|\n",
            "|KNITTED UNION FLA...|KNITTED UNION FLA...|\n",
            "|COLOR WOOLLY HOTT...|RED WOOLLY HOTTIE...|\n",
            "|SET 7 BABUSHKA NE...|SET 7 BABUSHKA NE...|\n",
            "|GLASS STAR FROSTE...|GLASS STAR FROSTE...|\n",
            "|HAND WARMER UNION...|HAND WARMER UNION...|\n",
            "|HAND WARMER COLOR...|HAND WARMER RED P...|\n",
            "|ASSORTED COLOUR B...|ASSORTED COLOUR B...|\n",
            "+--------------------+--------------------+\n",
            "only showing top 10 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import translate\n",
        "\n",
        "df.select(translate(col(\"Description\"), \"LEET\", \"1337\"),col(\"Description\")).show(2)\n",
        "\n",
        "#-- in SQL\n",
        "#SELECT translate(Description, 'LEET', '1337'), Description FROM dfTable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrdJ1x-p9LYv",
        "outputId": "9124970a-faf8-4f66-c7ba-1143a5e6da8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------+--------------------+\n",
            "|translate(Description, LEET, 1337)|         Description|\n",
            "+----------------------------------+--------------------+\n",
            "|              WHI73 HANGING H3A...|WHITE HANGING HEA...|\n",
            "|               WHI73 M37A1 1AN73RN| WHITE METAL LANTERN|\n",
            "+----------------------------------+--------------------+\n",
            "only showing top 2 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Working with Dates and Timestamps"
      ],
      "metadata": {
        "id": "gaxjmkOZ9v2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import current_date, current_timestamp\n",
        "\n",
        "dateDF = spark.range(10)\\\n",
        ".withColumn(\"today\", current_date())\\\n",
        ".withColumn(\"now\", current_timestamp())\n",
        "\n",
        "dateDF.createOrReplaceTempView(\"dateTable\")\n",
        "dateDF.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2WuX3Ni90zr",
        "outputId": "a3238f01-ef41-4150-f033-fdaac84a730c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: long (nullable = false)\n",
            " |-- today: date (nullable = false)\n",
            " |-- now: timestamp (nullable = false)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select * from dateTable\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUJ-58oF-D5S",
        "outputId": "646e12f7-2c2a-4cb7-a6d3-0a82bc2a8075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+--------------------+\n",
            "| id|     today|                 now|\n",
            "+---+----------+--------------------+\n",
            "|  0|2025-12-26|2025-12-26 18:42:...|\n",
            "|  1|2025-12-26|2025-12-26 18:42:...|\n",
            "|  2|2025-12-26|2025-12-26 18:42:...|\n",
            "|  3|2025-12-26|2025-12-26 18:42:...|\n",
            "|  4|2025-12-26|2025-12-26 18:42:...|\n",
            "|  5|2025-12-26|2025-12-26 18:42:...|\n",
            "|  6|2025-12-26|2025-12-26 18:42:...|\n",
            "|  7|2025-12-26|2025-12-26 18:42:...|\n",
            "|  8|2025-12-26|2025-12-26 18:42:...|\n",
            "|  9|2025-12-26|2025-12-26 18:42:...|\n",
            "+---+----------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import date_add, date_sub\n",
        "dateDF.select(date_sub(col(\"today\"), 5), date_add(col(\"today\"), 5)).show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16dyXCgM-Nz7",
        "outputId": "356b5e61-7006-40ec-ec35-ad4c0d739b8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+------------------+\n",
            "|date_sub(today, 5)|date_add(today, 5)|\n",
            "+------------------+------------------+\n",
            "|        2025-12-21|        2025-12-31|\n",
            "|        2025-12-21|        2025-12-31|\n",
            "|        2025-12-21|        2025-12-31|\n",
            "|        2025-12-21|        2025-12-31|\n",
            "|        2025-12-21|        2025-12-31|\n",
            "|        2025-12-21|        2025-12-31|\n",
            "|        2025-12-21|        2025-12-31|\n",
            "|        2025-12-21|        2025-12-31|\n",
            "|        2025-12-21|        2025-12-31|\n",
            "|        2025-12-21|        2025-12-31|\n",
            "+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import datediff, months_between, to_date\n",
        "\n",
        "dateDF.withColumn(\"week_ago\", date_sub(col(\"today\"), 7))\\\n",
        ".select(datediff(col(\"week_ago\"), col(\"today\"))).show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1D5LRzm-k3h",
        "outputId": "525ca399-3fa9-49a6-eabb-dc0ca28669f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------+\n",
            "|datediff(week_ago, today)|\n",
            "+-------------------------+\n",
            "|                       -7|\n",
            "+-------------------------+\n",
            "only showing top 1 row\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dateDF.select( to_date(lit(\"2026-01-01\")).alias(\"start\"),to_date(lit(\"2027-05-01\")).alias(\"end\"))\\\n",
        ".select(months_between(col(\"end\"), col(\"start\"))).show(1)\n",
        "\n",
        " #-- in SQL\n",
        " #SELECT to_date('2016-01-01'), months_between('2016-01-01', '2017-01-01'),\n",
        " #datediff('2016-01-01', '2017-01-01')\n",
        " #FROM dateTable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFwCIDyjA-4Y",
        "outputId": "0e755039-02a2-4464-a2d0-57aa9be1c1c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------+\n",
            "|months_between(end, start, true)|\n",
            "+--------------------------------+\n",
            "|                            16.0|\n",
            "+--------------------------------+\n",
            "only showing top 1 row\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import to_date\n",
        "\n",
        "dateFormat = \"yyyy-dd-MM\"\n",
        "cleanDateDF = spark.range(1)\\\n",
        "              .select(to_date(lit(\"2017-12-11\"), dateFormat).alias(\"date\"),\n",
        "              to_date(lit(\"2017-20-12\"), dateFormat).alias(\"date2\"))\n",
        "\n",
        "cleanDateDF.createOrReplaceTempView(\"dateTable2\")\n",
        "\n",
        "spark.sql(\"select * from dateTable2\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e5c4C3yBoPT",
        "outputId": "e4189551-709b-4bbb-ee14-6ac190e633c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+\n",
            "|      date|     date2|\n",
            "+----------+----------+\n",
            "|2017-11-12|2017-12-20|\n",
            "+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working with Nulls in Data"
      ],
      "metadata": {
        "id": "-a6L3LWACA7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The primary way of interacting with null values, at DataFrame scale, is to\n",
        "use the .na subpackage on a DataFrame\n",
        "\n",
        "There are two things you can do with null values:\n",
        "*   Can explicitly drop nulls\n",
        "*   or can fill them with a value (globally or on a per-column basis).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hI2w5e0wCNXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Spark includes a function to allow you to select the first non-null value from a set of columns by\n",
        "#using the coalesce function.\n",
        "from pyspark.sql.functions import col, coalesce\n",
        "\n",
        "df.select(\n",
        "    coalesce(col(\"Description\"), col(\"CustomerId\").cast(\"string\")).alias(\"final_value\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akSelDk4CFCp",
        "outputId": "a8caa54f-16cb-4bd2-a219-760690551511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|         final_value|\n",
            "+--------------------+\n",
            "|WHITE HANGING HEA...|\n",
            "| WHITE METAL LANTERN|\n",
            "|CREAM CUPID HEART...|\n",
            "|KNITTED UNION FLA...|\n",
            "|RED WOOLLY HOTTIE...|\n",
            "|SET 7 BABUSHKA NE...|\n",
            "|GLASS STAR FROSTE...|\n",
            "|HAND WARMER UNION...|\n",
            "|HAND WARMER RED P...|\n",
            "|ASSORTED COLOUR B...|\n",
            "|POPPY'S PLAYHOUSE...|\n",
            "|POPPY'S PLAYHOUSE...|\n",
            "|FELTCRAFT PRINCES...|\n",
            "|IVORY KNITTED MUG...|\n",
            "|BOX OF 6 ASSORTED...|\n",
            "|BOX OF VINTAGE JI...|\n",
            "|BOX OF VINTAGE AL...|\n",
            "|HOME BUILDING BLO...|\n",
            "|LOVE BUILDING BLO...|\n",
            "|RECIPE BOX WITH M...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  *   ifnull - ifnull allows to select the second value if the first is null, and defaults to the first.\n",
        "\n",
        "  *   nullIf - use nullif, which returns null if the two values are equal or else returns the second if they are not.\n",
        "\n",
        "  *   nvl- vl returns the second value if the first is null, but defaults to the first\n",
        "  *   nvl2 - nvl2 returns the second value if the first is not null; otherwise, it will return the last specified value"
      ],
      "metadata": {
        "id": "iHR63RX2S43t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** drop**\n",
        " The simplest function is drop, which removes rows that contain nulls. The default is to drop any\n",
        " row in which any value is null:\n",
        " *   df.na.drop()\n",
        " *   df.na.drop(\"any\")\n",
        "\n",
        "Specifying \"any\" as an argument drops a row if any of the values are null. Using â€œallâ€ drops the row only if all values are null or NaN for that row:\n",
        "*   df.na.drop(\"all\")"
      ],
      "metadata": {
        "id": "iVQpvQ_GTfFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.na.drop(\"all\", subset=[\"StockCode\", \"InvoiceNo\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ENC-TUCTzBm",
        "outputId": "8ecd6a65-50ca-4312-f4d2-51d22ca90bbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[InvoiceNo: string, StockCode: string, Description: string, Quantity: int, InvoiceDate: timestamp, UnitPrice: double, CustomerID: double, Country: string]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**fill**\n",
        "\n",
        "\n",
        " Using the fill function, we can fill one or more columns with a set of values. This can be done by specifying a mapâ€”that is a particular value and a set of columns.\n",
        "\n",
        " For example, to fill all null values in columns of type String, we might specify the following:\n",
        " df.na.fill(\"All Null values become this string\")"
      ],
      "metadata": {
        "id": "tJd-wKM8T8HG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " **replace**\n",
        "\n",
        "\n",
        "  df.na.replace([\"\"], [\"UNKNOWN\"], \"Description\")"
      ],
      "metadata": {
        "id": "D20FDREkUKVU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yTnHwirlTh2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.na.replace([\"\"], [\"UNKNOWN\"], \"Description\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOPEjcBZUOx3",
        "outputId": "91d41474-fb8a-4dd9-bd89-612592cc2d14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
            "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
            "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
            "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n",
            "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
            "|   536365|   84406B|CREAM CUPID HEART...|       8|2010-12-01 08:26:00|     2.75|   17850.0|United Kingdom|\n",
            "|   536365|   84029G|KNITTED UNION FLA...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
            "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
            "|   536365|    22752|SET 7 BABUSHKA NE...|       2|2010-12-01 08:26:00|     7.65|   17850.0|United Kingdom|\n",
            "|   536365|    21730|GLASS STAR FROSTE...|       6|2010-12-01 08:26:00|     4.25|   17850.0|United Kingdom|\n",
            "|   536366|    22633|HAND WARMER UNION...|       6|2010-12-01 08:28:00|     1.85|   17850.0|United Kingdom|\n",
            "|   536366|    22632|HAND WARMER RED P...|       6|2010-12-01 08:28:00|     1.85|   17850.0|United Kingdom|\n",
            "|   536367|    84879|ASSORTED COLOUR B...|      32|2010-12-01 08:34:00|     1.69|   13047.0|United Kingdom|\n",
            "|   536367|    22745|POPPY'S PLAYHOUSE...|       6|2010-12-01 08:34:00|      2.1|   13047.0|United Kingdom|\n",
            "|   536367|    22748|POPPY'S PLAYHOUSE...|       6|2010-12-01 08:34:00|      2.1|   13047.0|United Kingdom|\n",
            "|   536367|    22749|FELTCRAFT PRINCES...|       8|2010-12-01 08:34:00|     3.75|   13047.0|United Kingdom|\n",
            "|   536367|    22310|IVORY KNITTED MUG...|       6|2010-12-01 08:34:00|     1.65|   13047.0|United Kingdom|\n",
            "|   536367|    84969|BOX OF 6 ASSORTED...|       6|2010-12-01 08:34:00|     4.25|   13047.0|United Kingdom|\n",
            "|   536367|    22623|BOX OF VINTAGE JI...|       3|2010-12-01 08:34:00|     4.95|   13047.0|United Kingdom|\n",
            "|   536367|    22622|BOX OF VINTAGE AL...|       2|2010-12-01 08:34:00|     9.95|   13047.0|United Kingdom|\n",
            "|   536367|    21754|HOME BUILDING BLO...|       3|2010-12-01 08:34:00|     5.95|   13047.0|United Kingdom|\n",
            "|   536367|    21755|LOVE BUILDING BLO...|       3|2010-12-01 08:34:00|     5.95|   13047.0|United Kingdom|\n",
            "|   536367|    21777|RECIPE BOX WITH M...|       4|2010-12-01 08:34:00|     7.95|   13047.0|United Kingdom|\n",
            "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.na.replace([\"United Kingdom\"], [\"India\"], \"Country\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqUFL0k6UuGc",
        "outputId": "e739859f-37ea-487a-c0e1-2f34e05b49c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+--------------------+--------+-------------------+---------+----------+-------+\n",
            "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|Country|\n",
            "+---------+---------+--------------------+--------+-------------------+---------+----------+-------+\n",
            "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|  India|\n",
            "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|  India|\n",
            "|   536365|   84406B|CREAM CUPID HEART...|       8|2010-12-01 08:26:00|     2.75|   17850.0|  India|\n",
            "|   536365|   84029G|KNITTED UNION FLA...|       6|2010-12-01 08:26:00|     3.39|   17850.0|  India|\n",
            "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|2010-12-01 08:26:00|     3.39|   17850.0|  India|\n",
            "|   536365|    22752|SET 7 BABUSHKA NE...|       2|2010-12-01 08:26:00|     7.65|   17850.0|  India|\n",
            "|   536365|    21730|GLASS STAR FROSTE...|       6|2010-12-01 08:26:00|     4.25|   17850.0|  India|\n",
            "|   536366|    22633|HAND WARMER UNION...|       6|2010-12-01 08:28:00|     1.85|   17850.0|  India|\n",
            "|   536366|    22632|HAND WARMER RED P...|       6|2010-12-01 08:28:00|     1.85|   17850.0|  India|\n",
            "|   536367|    84879|ASSORTED COLOUR B...|      32|2010-12-01 08:34:00|     1.69|   13047.0|  India|\n",
            "|   536367|    22745|POPPY'S PLAYHOUSE...|       6|2010-12-01 08:34:00|      2.1|   13047.0|  India|\n",
            "|   536367|    22748|POPPY'S PLAYHOUSE...|       6|2010-12-01 08:34:00|      2.1|   13047.0|  India|\n",
            "|   536367|    22749|FELTCRAFT PRINCES...|       8|2010-12-01 08:34:00|     3.75|   13047.0|  India|\n",
            "|   536367|    22310|IVORY KNITTED MUG...|       6|2010-12-01 08:34:00|     1.65|   13047.0|  India|\n",
            "|   536367|    84969|BOX OF 6 ASSORTED...|       6|2010-12-01 08:34:00|     4.25|   13047.0|  India|\n",
            "|   536367|    22623|BOX OF VINTAGE JI...|       3|2010-12-01 08:34:00|     4.95|   13047.0|  India|\n",
            "|   536367|    22622|BOX OF VINTAGE AL...|       2|2010-12-01 08:34:00|     9.95|   13047.0|  India|\n",
            "|   536367|    21754|HOME BUILDING BLO...|       3|2010-12-01 08:34:00|     5.95|   13047.0|  India|\n",
            "|   536367|    21755|LOVE BUILDING BLO...|       3|2010-12-01 08:34:00|     5.95|   13047.0|  India|\n",
            "|   536367|    21777|RECIPE BOX WITH M...|       4|2010-12-01 08:34:00|     7.95|   13047.0|  India|\n",
            "+---------+---------+--------------------+--------+-------------------+---------+----------+-------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Ordering**\n",
        "\n",
        "\n",
        " use asc_nulls_first, desc_nulls_first, asc_nulls_last, or desc_nulls_last to specify where we would like null values to appear in an ordered DataFrame."
      ],
      "metadata": {
        "id": "MW5DTQO3UX7L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working with Complex Types"
      ],
      "metadata": {
        "id": "2-XyRDz7VAyD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are three kinds of complex types:\n",
        "*   Structs\n",
        "*   Arrays\n",
        "*   Maps"
      ],
      "metadata": {
        "id": "e2I6LF0-VF1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import struct\n",
        "complexDF = df.select(struct(\"Description\", \"InvoiceNo\").alias(\"complex\"))\n",
        "complexDF.createOrReplaceTempView(\"complexDF\")"
      ],
      "metadata": {
        "id": "TkDZ7ETon8ux"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select * from complexDF\").show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6jYG0NHoAK0",
        "outputId": "ed9be4bd-4ce3-4c55-fe5d-c864f4a430ea"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|             complex|\n",
            "+--------------------+\n",
            "|{WHITE HANGING HE...|\n",
            "|{WHITE METAL LANT...|\n",
            "+--------------------+\n",
            "only showing top 2 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "complexDF.show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEBwfhs2oSZf",
        "outputId": "840c9370-94f2-4d2b-e9fd-e884a83e29b0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|             complex|\n",
            "+--------------------+\n",
            "|{WHITE HANGING HE...|\n",
            "|{WHITE METAL LANT...|\n",
            "+--------------------+\n",
            "only showing top 2 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split**"
      ],
      "metadata": {
        "id": "k5n_0VYdokpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import split,col,size\n",
        "df.select(split(col(\"Description\"), \" \")).show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzPTciDZojcy",
        "outputId": "e1a9851e-dc9d-4179-d113-c4798e355879"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------+\n",
            "|split(Description,  , -1)|\n",
            "+-------------------------+\n",
            "|     [WHITE, HANGING, ...|\n",
            "|     [WHITE, METAL, LA...|\n",
            "+-------------------------+\n",
            "only showing top 2 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(split(col(\"Description\"), \" \").alias(\"array_col\"))\\\n",
        ".selectExpr(\"array_col[0]\").show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4TDpi4TourC",
        "outputId": "dbd46c6b-e5fa-4bcb-9a82-4f5ac50047c0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+\n",
            "|array_col[0]|\n",
            "+------------+\n",
            "|       WHITE|\n",
            "|       WHITE|\n",
            "+------------+\n",
            "only showing top 2 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(size(split(col(\"Description\"), \" \"))).show(2) # shows 5 and"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6x2pOEtXo1B6",
        "outputId": "e6a2df79-b733-4992-f610-d8f3618fc657"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------+\n",
            "|size(split(Description,  , -1))|\n",
            "+-------------------------------+\n",
            "|                              5|\n",
            "|                              3|\n",
            "+-------------------------------+\n",
            "only showing top 2 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import array_contains\n",
        "\n",
        "df.select(array_contains(split(col(\"Description\"), \" \"), \"WHITE\")).show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uDqsvpBpBQy",
        "outputId": "a130b00e-e4fa-445e-98f3-2d41a231ecfe"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------+\n",
            "|array_contains(split(Description,  , -1), WHITE)|\n",
            "+------------------------------------------------+\n",
            "|                                            true|\n",
            "|                                            true|\n",
            "+------------------------------------------------+\n",
            "only showing top 2 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explode**\n",
        "\n",
        "The explode function takes a column that consists of arrays and creates one row per value in the array."
      ],
      "metadata": {
        "id": "zxy7yL-ypKWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import explode\n",
        "\n",
        "df.withColumn(\"splitted\", split(col(\"Description\"), \" \"))\\\n",
        " .withColumn(\"exploded\", explode(col(\"splitted\")))\\\n",
        " .select(\"Description\", \"InvoiceNo\", \"exploded\").show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lbv_Tg6xpNmP",
        "outputId": "1a7ba8d1-6b5e-471e-8546-fa9429ae1fb8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+--------+\n",
            "|         Description|InvoiceNo|exploded|\n",
            "+--------------------+---------+--------+\n",
            "|WHITE HANGING HEA...|   536365|   WHITE|\n",
            "|WHITE HANGING HEA...|   536365| HANGING|\n",
            "+--------------------+---------+--------+\n",
            "only showing top 2 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Maps**\n",
        "\n",
        "In Spark, a Map is a data type that stores keyâ€“value pairs\n",
        "just like a dictionary in Python\n"
      ],
      "metadata": {
        "id": "GqOtZBMDpixo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# JSON support"
      ],
      "metadata": {
        "id": "gvBy3IAep5Gz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import from_json,to_json\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "parseSchema = StructType((\n",
        "StructField(\"InvoiceNo\",StringType(),True),\n",
        "StructField(\"Description\",StringType(),True)))\n",
        "\n",
        "df.selectExpr(\"(InvoiceNo, Description) as myStruct\")\\\n",
        ".select(to_json(col(\"myStruct\")).alias(\"newJSON\"))\\\n",
        ".select(from_json(col(\"newJSON\"), parseSchema), col(\"newJSON\")).show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBjp1Cqyp8Si",
        "outputId": "120d7e57-e8b7-4ec5-9b06-7476a356fc74"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+\n",
            "|  from_json(newJSON)|             newJSON|\n",
            "+--------------------+--------------------+\n",
            "|{536365, WHITE HA...|{\"InvoiceNo\":\"536...|\n",
            "|{536365, WHITE ME...|{\"InvoiceNo\":\"536...|\n",
            "+--------------------+--------------------+\n",
            "only showing top 2 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# User Defined Function(UDF)"
      ],
      "metadata": {
        "id": "ri7xLJUgqNeL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write your own custom transformations using Python or Scala and even use external libraries.Theyâ€™re just functions that operate on the data, record by record. By default, these functions are registered as temporary functions to be used in that specific SparkSession or Context.\n",
        "\n",
        "There are performance considerations that should be aware of\n",
        ""
      ],
      "metadata": {
        "id": "XuaDm4c-qS0R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qyUTqUW6qfSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #Step 1:\n",
        "def power3(double_value):\n",
        "  return double_value ** 3"
      ],
      "metadata": {
        "id": "4OZe_AY3qo59"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "udfExampleDF = spark.range(5).toDF(\"num\")\n",
        "power3(2.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cA17o4NIqkAn",
        "outputId": "e3eecdd3-fa4a-463b-ea8e-c442233e74ae"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.0"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "udfExampleDF.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-E9nip1qxFw",
        "outputId": "aa852f93-708c-4447-9b5c-792f12704903"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "|num|\n",
            "+---+\n",
            "|  0|\n",
            "|  1|\n",
            "|  2|\n",
            "|  3|\n",
            "|  4|\n",
            "+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2:\n",
        " #we need to register them with Spark so\n",
        " #that we can use them on all of our worker machines. Spark will serialize the function on the\n",
        " #driver and transfer it over the network to all executor processes.\n",
        "\n",
        "from pyspark.sql.functions import udf\n",
        "power3udf = udf(power3)\n",
        ""
      ],
      "metadata": {
        "id": "Te6R8q14q1wN"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Step 3:\n",
        " #we can use it in our DataFrame code:\n",
        "\n",
        "from pyspark.sql.functions import col\n",
        "udfExampleDF.select(power3udf(col(\"num\"))).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poN05QXSq7j7",
        "outputId": "3fcc58d6-e6ef-4411-874c-a86cce805050"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|power3(num)|\n",
            "+-----------+\n",
            "|          0|\n",
            "|          1|\n",
            "|          8|\n",
            "|         27|\n",
            "|         64|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}