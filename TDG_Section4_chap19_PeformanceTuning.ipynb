{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "nDFTDFW4qYW1",
        "1E9BLZZkwc7_"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Performance Tuning**"
      ],
      "metadata": {
        "id": "BWlCjs6_qUCj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Indirect Performance Enhancements"
      ],
      "metadata": {
        "id": "nDFTDFW4qYW1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can do indirectly by setting configuration values or changing the runtime environment which improve things across Spark Applications or across Spark jobs"
      ],
      "metadata": {
        "id": "gDfUYO6vqb9O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Design Choices**\n",
        "\n",
        "*  Language used for application development - Scala versus Java versus Python versus R\n",
        "*  DataFrames versus SQL versus Datasets versus RDDs\n",
        "*  To register your classes, use the SparkConf  and pass in the names of your\n",
        "classes: conf.registerKryoClasses(Array(classOf[MyClass1], classOf[MyClass2]))\n",
        "\n",
        "*  Dynamic allocation : set spark.dynamicAllocation.enabled to true.\n",
        "https://spark.apache.org/docs/latest/job-scheduling.html#configuration-and-setup"
      ],
      "metadata": {
        "id": "88330wdnq1r5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scheduling**\n",
        "\n",
        "Inside a Spark application (SparkContext instance), multiple parallel jobs can run simultaneously if they were submitted from separate threads.\n",
        "example:\n",
        "* Same SparkContext, different threads\n",
        "\n",
        "\n",
        "```\n",
        "thread1 -> df1.count()\n",
        "\n",
        "thread2 -> df2.write.parquet(...)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Spark’s DAGScheduler can schedule these jobs at the same time\n",
        "By default, Spark’s scheduler runs jobs in FIFO fashion\n",
        "\n",
        "Each job is divided into “stages” first job gets priority on all available resources while its stages have tasks to launch, then the second job gets priority and so on\n",
        "\n",
        "If the jobs at the head of the queue don’t need to use the whole cluster, later jobs can start to run right away, but if the jobs at the head of the queue are large, then later jobs may be delayed significantly.\n",
        "\n",
        "To enable the fair scheduler,simply set the spark.scheduler.mode property to FAIR when configuring a SparkContext\n",
        "`conf.set(\"spark.scheduler.mode\", \"FAIR\")`"
      ],
      "metadata": {
        "id": "OWmL35ykrN-h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fair Scheduler Pools**\n",
        "\n",
        "Fair Scheduler Pools are a feature of Spark’s FAIR scheduling mode\n",
        "\n",
        "2 pools: analytics & etl\n",
        "\n",
        "Spark tries to give 4 executors each\n",
        "Unless one pool is idle → then the other can use more\n",
        "\n",
        "\n",
        "```\n",
        "spark.sparkContext.setLocalProperty(\"spark.scheduler.pool\", \"etl\")\n",
        "df_etl.write.format(\"delta\").save(...)\n",
        "\n",
        "spark.sparkContext.setLocalProperty(\"spark.scheduler.pool\", \"analytics\")\n",
        "df_analytics.count()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "r-tvIolStTtl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Shuffle Configurations**\n",
        "\n",
        "A shuffle happens when Spark needs to redistribute data across partitions, e.g. during:groupBy, reduceByKey,join, distinct, orderBy,repartition\n",
        "\n",
        "Shuffle is expensive (disk + network), so tuning matters\n",
        "\n",
        "spark.sql.shuffle.partitions = 200   (default)\n",
        "\n",
        "For small/medium data: 50–100\n",
        "\n",
        "For large data: (total cores × 2–4)\n",
        "\n",
        "On databricks: SET spark.sql.shuffle.partitions = 100;\n",
        "\n",
        "\n",
        "**Shuffle File Buffer** - Buffer size when writing shuffle files to disk\n",
        "\n",
        "spark.shuffle.file.buffer = 32k\n",
        "\n",
        "**Shuffle Spill Compression** - compresses data spilled to disk and transferred over network\n",
        "\n",
        "```\n",
        "spark.shuffle.spill.compress = true\n",
        "spark.shuffle.compress = true\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "**Shuffle I/O Retry & Timeout**\n",
        "\n",
        "```\n",
        "useful in :\n",
        "Cloud environments (Azure/AWS)\n",
        "Intermittent network issues\n",
        "\n",
        "Increase retries for stability:\n",
        "spark.shuffle.io.maxRetries = 3\n",
        "spark.shuffle.io.retryWait = 5s\n",
        "\n",
        "spark.shuffle.io.maxRetries = 10\n",
        "spark.shuffle.io.retryWait = 10s\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J2KmHosbthvR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adaptive Query Execution** (Very Important)\n",
        "\n",
        "```\n",
        "spark.sql.adaptive.enabled = true\n",
        "spark.sql.adaptive.coalescePartitions.enabled = true\n",
        "spark.sql.adaptive.skewJoin.enabled = true\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "JNh7k2oIwP15"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Direct Performance Enhancements"
      ],
      "metadata": {
        "id": "1E9BLZZkwc7_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parallelism**\n",
        "\n",
        "Parallelism helps to process large amount of data by distributing at least 2 or 3 tasks per CPU core in the cluster\n",
        "\n",
        "Set spark.default.parallelism property as well as tuning the spark.sql.shuffle.partitions\n",
        "\n",
        "According to the number of cores in the cluster\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "example :\n",
        "Cluster details\n",
        "Worker nodes: 2\n",
        "Cores per node: 4\n",
        "Total cores = 8\n",
        "\n",
        "Parallelism ≈ 2–4 × total executor cores\n",
        "\n",
        "spark.default.parallelism = 16\n",
        "spark.sql.shuffle.partitions = 16\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "IY1JJTpuwfO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Filtering**\n",
        "\n",
        "Advisable to move filters to the earliest part of Spark job\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "df.filter(\"country = 'IN' OR country = 'US'\")\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "iE3w_LfFyAdr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Repartitioning**\n",
        "\n",
        "Repartition calls can incur a shuffle but still helps overall optimize jobs across cluster\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "example: df_repart = df.repartition(8, \"customer_id\") --> Rows with same customer_id go to same partition\n",
        "Repartition before aggregation --Avoids skewed partitions during aggregation\n",
        "df_agg = (\n",
        "    df.repartition(\"region\")\n",
        "      .groupBy(\"region\")\n",
        "      .sum(\"revenue\")\n",
        ")\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "WRurGpG9yxP0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Coalescing**\n",
        "\n",
        "Coalesce do not perform shuffle and merge partitions on the same node into one partition\n",
        "\n",
        "Reduce partitions after filtering\n",
        "\n",
        "```\n",
        "f_filtered = df.filter(\"year = 2024\")\n",
        "df_final = df_filtered.coalesce(4)\n",
        "```\n",
        "\n",
        "```\n",
        "Coalesce before writing (most common use case)\n",
        "df.coalesce(1).write.mode(\"overwrite\").parquet(\"/output/report\")\n",
        "df.coalesce(1) means: Reduce the DataFrame to exactly one partition, without doing a full shuffle.\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WgaxCgK7zPjs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**User defined function**\n",
        "\n",
        "In general, avoiding UDFs is a good optimization opportunity\n",
        "UDFs are expensive because they force representing data as objects in the JVM and sometimes do this multiple times per record in a query\n",
        "\n",
        "Since data is treated as object so it needs to be casted"
      ],
      "metadata": {
        "id": "u-ykvI-3z_EP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Temporary Data Storage (Caching)**\n",
        "\n",
        "Caching will place a DataFrame, table, or RDD into temporary storage (either memory or disk) across the executors in the cluster, and make subsequent reads faster.\n",
        "\n",
        "Caching data incurs a serialization, deserialization, and storage cost.\n",
        "\n",
        "Caching is a lazy operation, meaning that things will be cached only as they are accessed.\n",
        "You might be expecting to access raw data but because someone else already cached the data, you’re actually accessing their cached version.Keep that in mind when using this feature"
      ],
      "metadata": {
        "id": "5ljQ6AB-0Km4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Joins**\n",
        "\n",
        "Joins are a common area for optimization.\n",
        "\n",
        "Optimizing joins is simply educating about what each join does and how it’s performed."
      ],
      "metadata": {
        "id": "bz5Z_teF0cqT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Aggregations**\n",
        "\n",
        "Filtering data before the aggregation"
      ],
      "metadata": {
        "id": "H3qE62nQ0lxC"
      }
    }
  ]
}