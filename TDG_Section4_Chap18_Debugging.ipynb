{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Debugging**"
      ],
      "metadata": {
        "id": "dTVd8A8qFdJo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "some signs and symptoms of problems in Spark jobs"
      ],
      "metadata": {
        "id": "as72xKWwFkDA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Common Spark issues**"
      ],
      "metadata": {
        "id": "bgwpOGLVFwTP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spark Jobs Not Starting**\n",
        "\n",
        "During the process of setting up the cluster, we likely configured something incorrectly, and now the node that runs the driver cannot talk to the executors\n",
        "\n",
        "This is most likely a cluster level, machine, or configuration issue. Another option is that the application requested more resources per executor than cluster manager currently has free,in which case the driver will be waiting forever for executors to be launched.\n",
        "\n",
        "Ensure that machines can communicate with one another on the ports.Ideally, we should open up all ports between the worker nodes unless you have more\n",
        "stringent security constraints."
      ],
      "metadata": {
        "id": "fWs0g4NKF5QR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Errors During Execution**"
      ],
      "metadata": {
        "id": "kuWKy9kdG1dY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Signs**\n",
        "\n",
        "\n",
        "*  One Spark job runs successfully on the cluster but the next one fails\n",
        "*  A step in a multistep query fails\n",
        "*  A scheduled job that ran yesterday is failing today\n",
        "*  Difficult to parse error message\n"
      ],
      "metadata": {
        "id": "Q865kGTvqtGj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Potential treatments**\n",
        "\n",
        "Check to see if data exists or is in the format that is expected\n",
        "This can change over time or some upstream change may lead to unintended consequences on application\n",
        "\n",
        "Read through the stack trace to try to find clues about what components are involved\n",
        "\n",
        "If a job execute tasks for some time and then fails, it could be due to a problem with the input data itself, wherein the schema might be specified incorrectly or a particular row does not conform to the expected schema.\n",
        "\n",
        "You will see a task marked as “failed” on the Spark UI, and you can also view the logs on that machine to understand what it was doing when it failed.Try adding more logs inside your code to figure out which data record was being processed\n"
      ],
      "metadata": {
        "id": "6JimorWDrEAd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Slow Tasks or Stragglers**"
      ],
      "metadata": {
        "id": "JxCZcdrOtKt8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sign**\n",
        "\n",
        "Due to work not being evenly distributed across your machines (“skew”), or due to one of your machines being slower than the others\n",
        "\n",
        "Scaling up the number of machines given to the Spark Application doesn’t really help.some tasks still take much longer than others.\n",
        "\n",
        "In the Spark metrics, certain executors are reading and writing much more data than others\n",
        "\n",
        "Slow tasks are often called “stragglers.” There are many reasons they may occur, but most often the source of this issue is that the data is partitioned unevenly into DataFrame.When this happens, some executors might need to work on much larger amount of data than others.\n",
        "Example- group-by-key operation, one of the key has more data than others\n",
        "In this case, when we look at the Spark UI, we might see the shuffle data for some nodes is much larger than for others\n",
        "\n",
        "\n",
        "**Treatment**\n",
        "\n",
        "*  Try increasing the number of partitions to have less data per partition.\n",
        "*  Try repartitioning by another combination of columns\n",
        "*  Try increasing the memory allocated to executors if possible.\n",
        "*  Monitor the executor that is having trouble and see if it is the same machine across jobs.Might be an unhealthy executor or machine in the cluster. for example : one whose disk is nearly full.\n",
        "*  Check the slow tasks is associated with join or an aggregation\n",
        "\n",
        "\n",
        "Note : Stragglers can be one of the most difficult issues to debug, simply because there are so many possible causes. However, in all likelihood, the cause will be some kind of data skew, so definitely begin by checking the Spark UI for imbalanced amounts of data across tasks"
      ],
      "metadata": {
        "id": "7Mm716CBtMhf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Slow Aggregations**"
      ],
      "metadata": {
        "id": "HibESvFlv4Qv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sign**\n",
        "* GroupBy call slows down the tasks. Data in the job just has some skewed keys\n",
        "\n",
        "**Treatment**\n",
        "\n",
        "*  Increasing the number of partitions, prior to an aggregation\n",
        "*  Repartition data\n",
        "*  Increasing executor memory\n",
        "*  Work only on those data that is needed\n",
        "*  Ensure null values are represented correctly (using Spark’s concept of null) and not as some default value like \" \" or \"EMPTY\"\n"
      ],
      "metadata": {
        "id": "rX3kwOU2v7Gr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Slow Joins**"
      ],
      "metadata": {
        "id": "KzSPv3jsyDN9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  Joins and aggregations both shuffles data across nodes.Experimenting with different join orderings can really help speed up jobs.especially if\n",
        "some of those joins filter out a large amount of data, do those first.\n",
        "\n",
        "*  Partitioning a dataset prior to joining can be very helpful for reducing data movement across the cluster\n",
        "\n",
        "*  Slow joins can also be caused by data skew. Increasing the size of executors can help\n",
        "\n",
        "*  Only required data is used in Joins\n",
        "\n",
        "*  Ensure that null values are handled correctly\n",
        "*  If you know that one of the tables that you are joining is small, you can try to force a broadcast.Use Spark’s statistics collection commands to let it analyze the table.\n",
        "\n",
        "    \n",
        "\n",
        "```\n",
        "#   ANALYZE TABLE table_name COMPUTE STATISTICS;\n",
        "      ANALYZE TABLE table_name COMPUTE STATISTICS FOR COLUMNS column1, column2;\n",
        "      ANALYZE TABLE sales COMPUTE STATISTICS FOR ALL COLUMNS;\n",
        "```\n",
        "DESCRIBE EXTENDED table_name;\n",
        "SET spark.sql.statistics.histogram.enabled = true;\n",
        "\n",
        "```\n",
        "# Join-heavy queries\n",
        "Large Delta tables\n",
        "Cost-based optimization (CBO)\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "ntKQUFl_yFHq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Driver OutOfMemoryError or Driver Unresponsive**\n",
        "\n",
        "*  Collecting too much data back to the driver, making it run out of memory. The code might have tried to collect an overly large dataset to the driver node using operations such as collect.\n",
        "\n",
        "*  You might be using a broadcast join where the data to be broadcast is too big\n",
        "\n",
        "*  Use Spark’s maximum broadcast join configuration to better control the size it will broadcast.\n",
        "\n",
        "\n",
        "spark.sql.autoBroadcastJoinThreshold --> maximum size (in bytes) of a table that Spark will automatically broadcast to all executors during a join\n",
        "\n",
        "SET spark.sql.autoBroadcastJoinThreshold = 50MB;\n",
        "\n",
        "Keep broadcast tables: < executor memory × safety margin\n",
        "\n"
      ],
      "metadata": {
        "id": "c-3ZmHA-0MgP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Serialization Errors**\n",
        "\n",
        "*  Data you are trying to share cannot be serialized.\n",
        "*  Verify that you’re actually registering your classes so that they are indeed serialized."
      ],
      "metadata": {
        "id": "-OPklxdT3c3Z"
      }
    }
  ]
}